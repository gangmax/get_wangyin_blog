## AlphaGo与人工智能

![](http://upload-images.jianshu.io/upload_images/68562-585d20981fef6a5b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/300)

在之前的一篇[文章](http://www.jianshu.com/p/01d1b2542036)中我指出，自动驾驶所需要的“视觉识别能力”和“常识判断能力”，对于机器来说是非常困难的问题。至今没有任何机器，可以在视觉方面达到驴的水平，更不要说和人比。可是最近Google的[AlphaGo](https://deepmind.com/alpha-go.html)战胜了围棋世界冠军，闹得沸沸扬扬。

本来是玩个游戏，偏要吹成是“历史性的人机大战”，说得好像是机器挑战了人类的智能，伤了人类的自尊似的。这整个项目打着一个相当高大上的招牌，叫做“[Deep Mind](http://deepmind.com)”。当然，其中的技术也有一些吓人的名字，什么“神经网络”啊，“深度学习”啊……

听到这些，总有一知半解的人，根据科幻电影的情节开始展望，这样厉害的技术，应该可以用来做其它更加“智能”的事情，然后就开始对“人类的未来”作出一些杞人忧天的猜想，说人类的工作很快都要被机器取代了，甚至[Skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator))就要实现了，云云。

我只想在这里给这些人提个醒：别做科幻梦了，回到现实吧。

### 不同AI问题的难度比较

一个常见的外行想法，是以为AlphaGo真的具有“人类智能”，所以Google利用同样的技术，可以实现自动车。这些人大大的高估了所谓“AI”的能力不说，他们也不明白，不同的“AI问题”的难度，其实有着天壤之别——机器视觉和自动车，是比下围棋困难很多的问题。

要知道，机器下棋的对手是人，而机器视觉和自动车的对手，却是天。预测人下棋的招数比较容易，然而天有不测风云。很难想象，一个机器要如何预测马路上可能出现的各种危险情况。一个很简单的例子，前面的车子顶上绑了一个东西，可是没有绑稳，摇摇欲坠的样子。人一眼就看出来了，然而这对于机器视觉，却是非常困难的问题。机器识别物体是非常困难的问题，更不要说还得识别出它们所处的状态（稳定，还是摇摇欲坠），所以机器很难判断出这种危险的存在。所以自动车根本不会察觉这种危险，它不会选择换个车道，避让这辆车，然后尽快超过去。跟二愣子一样，继续跟着前面的车走，使得乘客处于危险之中。

所以视觉识别和自动驾驶比起下围棋，难度其实要大许多倍，根本不在一个量级。机器视觉，并不是AlphaGo所用的树搜索和神经网络那么简单的方法就可以解决的。由于需要以极高的速度处理“模拟信号”，它可能根本就不是人们常用的“数字计算机”可以解决的问题。也就是说，不是写代码就可以搞定的。

其实很早以前，人工智能专家们就发现一个很有趣的现象，是这样：

*   对于人来说很难，很烦的事情（复杂的计算，下棋，推理……），对于计算机来说，其实算是相对容易的事情。
*   对于人来说很容易的事情（认人，辨别物品，走路，开车，打球……），对于计算机来说，却非常困难。
*   计算机需要精确的，离散的，死板的输入。它们不能适应环境的改变。
*   人擅长于处理模糊的，连续的，不完美的数据，对环境的适应能力非常高。

### 棋类是相对容易的AI问题

从以上几点你可以看出，象棋，围棋等活动，正好符合了计算机的特点。棋类活动都具有离散的，精确的，有限的输入。棋盘上就那么几十，几百个点，不是随便放在哪里都可以的。一人走一步，轮流着走，不能乱来。整个棋盘的信息是完全可见的，没有隐藏的，缺损的信息。棋局的“解空间”虽然很大，却非常规整，有规律可循。围棋的第一步可以有361种情况，第二步有360种情况，……

计算机利用自己的“计算暴力”，可以有计划有步骤，兢兢业业的把各种可能出现的情况算出来，一直到许多步以后，然后从中选择最有优势的走法。所以下棋归根结底，就是一个“树搜索”问题，只不过因为规模太大，需要加入一些优化。围棋的解空间虽然大，却是一个已知数，它最多有250<sup>150</sup>种情况。AlphaGo使用所谓“神经网络”，就是为了在搜索的时候进行优化，尽早的排除不大可能取胜的情况，免得浪费计算的时间。

这种精确，死板，机械化，主要靠“暴力”的活动，就跟计算一个比较大的乘法算式（比如2463757 x 65389）的性质类似，只不过规模大很多。显然，人做这类事情很繁，很累，很容易出错，计算机对此却具有先天的优势，因为它是一个机器。当年“深蓝”战胜国际象棋世界冠军的时候，我就已经预测到，计算机成为围棋世界冠军是迟早的事，所以我早就不屑于下任何棋了。可惜的是，挺多人仍然把精通棋艺作为一种荣耀（因为“琴棋书画剑”嘛）。我不关心围棋已经十多年了，只记得十年前很多中国人认为，中国人下围棋总是输给韩国人，是一种耻辱。现在看来，这是多么可笑的事情。这就像因为心算乘法不如韩国人快，就觉得是耻辱一样。

现在AlphaGo在围棋方面战胜了人，正好说明棋类游戏根本就不是值得人去做的事情 :)

### “琐事”才是真正困难的AI问题

现在来对比一下人们生活中的琐事，就说倒水端茶吧。

![](http://upload-images.jianshu.io/upload_images/68562-a2a10fbeb02f06e3.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/240)

让一个机器来给你倒水，有多难呢？意想不到的难！看看这个场景，如果你的电脑配备有摄像头，那么它怎么知道茶壶在哪里呢？要知道，茶壶的材料，颜色，形状，和角度，可以有几乎无穷多的变化。甚至有些茶壶跟哈哈镜一样，会把旁边的物体的形状都扭曲反射出来。桌上的物品附近都有各种反光和阴影，不同材料的反光特性还不一样，这些都会大幅度的影响机器对物品的识别。

为了识别物体，机器需要常识，它的头脑里必须有概念，必须知道什么样的东西才能叫做“茶壶”和“茶杯”。不要小看这一步的难度，这意味着机器必须理解基本的“拓扑结构”，什么叫做“连续的平面”，什么叫做“洞”，什么是“凹”和“凸”，什么是“里”和“外”…… 另外，这机器必须能够分辨物体和阴影。它必须知道水是什么，水有什么样的运动特性，什么叫做“流动”。它必须知道“水往低处流”，然后它又必须知道什么叫“低”和“高”…… 它必须知道茶杯为什么可以盛水，茶壶的嘴在哪里，把手在哪里，怎样才能拿起茶壶。如果一眼没有看见茶壶的把手，那它在哪里？茶壶的哪一面是“上面”，要怎样才可以把水从茶壶的嘴里倒出来，而不是从盖子上面泼出来？什么是裂掉的茶杯，它为什么会漏水，什么是缺口的茶杯，它为什么仍然可以盛水而不漏？干净的茶杯是什么样子的，什么是脏的茶杯，什么是茶垢，为什么茶垢不算是脏东西？如何控制水的流速和落点，什么叫做“水溅出来了”，要怎么倒水才不会溅出来？……

你也许没有想到，倒茶这么简单的事情，需要用到如此多的常识。所有这些变数加在一起，其实远远的大于围棋棋局的数量，人却可以不费力的完成。这能力，真是应该让人自己都吓一跳，然而人却对此不以为然，称之为“琐事”！因为其他人都可以做这样的事情，甚至猴子都可以，怎么能显得出我很了不起呢？人的自尊和虚荣，再一次的蒙蔽了他自己。他没有意识到，这其实是非常宝贵，让机器难以匹敌的能力。他闭上眼睛说道：“机器经过大量的学习，总有一天会做到的。看我们有神经网络呢，还有深度学习！”

学习，说起来真的不费力气。好一个万能的解决方案——学习。可是辨别物体的能力，真的可以通过学习得到吗？很多人没想到的是，这看似学习的结果，而其实都是每个人生下来就已经固化在脑子的“硬件”里的，不是短短几个月或者几年的“学习”就能得到的。所有的高等动物都有这种功能，所以这其实已经耗费了自然界几百万年，甚至上亿年的功夫来“研究”，“开发”，“学习”。小孩子似乎很快就学会了这些能力，而其实这种所谓的“学习”，只不过是“激活”了这些早就写进了人类DNA里的功能。

### 机器的局限性

著名的认知科学家[Douglas Hofstadter](http://www.theatlantic.com/magazine/archive/2013/11/the-man-who-would-teach-machines-to-think/309529)（《[GEB](https://en.wikipedia.org/wiki/G%C3%B6del,_Escher,_Bach)》的作者），早就指出AI领域的那些热门话题，比如电脑下棋，跟真正意义上的人类智能，几乎完全不搭边。绝大部分人其实不明白，思考和智能到底是什么，人类的长处究竟在那里。大部分所谓AI专家，对人脑的工作原理所知甚少，甚至完全不关心，却总喜欢闭着眼睛说：“人脑只不过是一台计算机！”

不管AI专家们怎么瞎掰，人脑跟电脑仍然有着根本性的不同。一个很显然的事实是，人脑并不是一台数字计算机。人脑可以直接处理模拟信号，而不需要把它们进行数字化，这使得它的速度比数字计算机快很多个数量级。另外，人脑里的“线路”其实是活动的，是可以重新连接的，并不像电脑那样是金属焊死在那里，固定的。这使得人可以通过训练，产生专门的线路，非常高效的处理某些高速的活动（比如打球，开车）。人脑具有“意识”，而机器没有。我们至今还没有搞明白，意识到底是什么。当然，人脑的奇特之处远远不止这些。所以要实现接近人类级别的智能，你似乎只有把机器做得越来越像人。可是现在我们连人脑到底是怎么工作的都不知道，甚至不能可靠地hack进人脑，改变它的记忆和思维，又何谈实现所谓“人类智慧”呢？

AI领域似乎喜欢提出各种又大又空，唬人的名词，比如“神经网络”，“机器学习”。后来发现大家都看破了机器学习，不过就是一些统计学方法贴了个新标签，搞得乌七八糟，所以又提出所谓“深度学习”，想让人继续摸不着头脑，从而产生敬畏之情…… 可是随他们怎么扯，人脑和计算机仍然有着根本性的不同。人类最宝贵的能力，并不是能很快的，机械的做出算术题，或者能够在棋类游戏中胜出。人怎么也没想到，自己最宝贵的特殊能力，其实是每个人都能做的那些生活琐事：端茶，倒水，开门，走路，……

机器虽然在围棋一类的“高智商”活动能够战胜人，可是你要它做这些“简单”的琐事，却发现意想不到的难！也许不是不可能，但确实有很难逾越的鸿沟。问题在于：

*   机器缺少动物所具有的感官。虽然机器可以有各种传感器，激光，雷达，…… 然而就算配备了如此大型，精密，远距离的设备，接收大量的数据，机器对于日常事物（比如茶杯，乒乓球等）的判断和控制能力，却远远不如人那两只小小的，近视的眼睛。它更不能跟视觉更加敏锐的动物，比如猫，狼，鹰，相比拟。

    眼睛是一种异常先进的设备，它的工作原理跟人造的传感器，摄像头，激光，雷达，有着根本性的不同。看看这些“[光学幻觉](http://www.michaelbach.de/ot)”之后，你也许会明白，眼睛和视觉神经，远远不止是摄像机那么简单。人的视觉系统，根本不需要主动发射出电磁波或者超声波，根本不需要接收很精确，很大量的数据。它只需要被动的接收少量的光线，就能准确的把握事物的形态和运动规律。它不但能处理看得见的信号，而且能根据已有的常识，很快的补充出[看不见的部分](http://www.michaelbach.de/ot/mot-breathingSquare/index.html)。视觉神经对于运动的物体，具有自动的[追踪和适应能力](http://www.michaelbach.de/ot/mot-adapt/index.html)，以至于产生所谓“运动后效应”（motion aftereffect）。它能够根据非常少的数据，组合出背后的[抽象物体](http://www.michaelbach.de/ot/mot-biomot/index.html)。这些都是现有的机器很难做到的事情。

*   来自世界的信息是不完美的，模糊的。计算机需要非常精确的输入，不能容纳和处理不完美的，模糊的，有误差的数据，不能适应输入的变化。比如，也许一个机器人认得一个特定的杯子，然后你把这杯子倒着放，或者把它打缺一个口子，它就不认得这是一个杯子了。

*   计算机缺乏人所具有的常识。所谓常识，就是一些人所皆知，想都不用想的事情。就像“什么是杯子”，“什么是猫”，“水往低处流”，“如何用手把东西拿起来”之类。计算机不具有人类的感官，不能过人类的生活，不具有人类的学习能力，适应环境的能力，所以它们几乎不可能获得人类的常识。

### 机器学习是什么

Hofstadter说：“计算机要得到人类一样的智慧，得先长上脚，能够走路，能够跟人一起生活，能够跟人交流。它必须有很好的感官，能够感觉到这个世界，能够体验生活，这样它才能学到常识……” 然而，机器跟人却有着根本性的不同。你不能简单的给机器人装上腿脚和传感器，让它跟人学习。机器的“头脑”跟人脑不一样，它没有意识，它不能形成“概念”。就像你把一个石头放在身边，它什么也学不会一样，计算机其实并没有比石头聪明很多。

很多人喜欢拿“机器学习”来吓唬人，以为出现了“学习”两个字，就有了万能的解决方案。而其实呢，机器学习说白了，只不过是通过大量的数据，统计拟合出某些函数的参数。比如你可以猜测一组二维的数据点，符合一个简单的函数 y = ax<sup>3</sup> + bx<sup>2</sup> + cx + d，但不知道a, b, c和d该是多少。于是你就利用所谓“机器学习”，也就是通过数学统计，猜出参数a, b, c和d的值，使得这个函数符合采集到的数据。可是这函数是怎么来的呢？终究还是人想出来的！机器无论如何也跳不出 y = ax<sup>3</sup> + bx<sup>2</sup> + cx + d这个框子。如果数据不符合这个范式，还是只有靠人，才能找到更加符合数据特性的函数。

所谓神经网络其实也是一个函数，它在本质上跟y = ax<sup>3</sup> + bx<sup>2</sup> + cx + d并没有不同，只不过输入的参数多一些，逻辑复杂一些。所以“神经网络”跟神经，其实完全没有关系。“神经网络”是一个非常聪明的广告词，它不知道用迷惑了多少人。因为有“神经”两个字在里面，很多人就以为它会让机器具有智能，而其实这些就是统计学家门斯通见惯的事情：拟合一个函数。你可以拟合出很好的函数，然而这跟“智能”没有任何关系。

### AlphaGo的算法要点

（这小节含有技术细节。不熟悉计算机算法和AI的人士，可以跳跃性的阅读这一节。）

看到AlphaGo取胜，就以为Skynet就要实现的那些人，其实不明白人工智能的难点在哪里。他们可能根本没上过基本的AI课程，没有扎扎实实的实现过[A*](https://en.wikipedia.org/wiki/A*_search_algorithm)之类的“图搜索”算法，也不知道所谓“神经网络”，跟神经其实没有屁点关系。

如果你真的领会了A*搜索的精髓，就会发现[AlphaGo的论文](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)里所描述的算法，其实是A*算法的一个特例。A*算法，本质上就是我们常见的[广度优先搜索](https://en.wikipedia.org/wiki/Breadth-first_search)算法的一个推广。广度优先算法中，对每一层的节点，都是从左到右按顺序展开，而A*算法不是从左到右，而是从中选择“最优”的节点，对它优先进行展开。如果没有找到答案，再考虑其它的分支。这种“剪枝”的做法，可以节省大量的计算时间。选择“最优分支”的要点，在于找到一个好的“启发函数”（heuristic），这个函数能很快的告诉你，从当前的搜索状态，经过某种“捷径”，能够得到的最佳结果。

AlphaGo所谓的“policy networks”和“value networks”组合在一起，就相当于A*算法的启发函数。AlphaGo通过对三千万个大师级“棋局点”的统计分析，事先算出了大师们在各种棋局状态下，最有可能下子位置的概率分布。然后，AlphaGo根据这个概率分布，进行所谓“蒙特卡洛树搜索”（MCTS），快速的推算如果走某一步，在“最幸运”的情况下，是否有可能取胜。如果在最幸运的情况下都没可能取胜，那走这步肯定会输了，所以之后的步骤都可以省略，从而节省计算的时间。

这样的数据分析，在某种程度下对人类棋手是不公平的。因为AlphaGo分析了太多的历史数据，它能预测到在每种情况下，你最可能会走哪一步。人类棋手一般不会分析如此多的数据，而且AlphaGo刚出道，都没有什么历史记录可以拿来分析，所以人在“战略”准备上处于劣势。

这种对大量棋局的分析，其实也说明AlphaGo并没有很高的“智能”可言。它并不是真的对围棋这件事很在行，而只是对自己的对手了如指掌。所以这机器其实主要是通过死记硬背，外加暴力来取胜的，并不是靠自己的“直觉”或者“聪明才智”。这样的算法，也许可以很好地应付经常遇到的情况。然而一旦身处未知的世界，很可能就会摸不着头脑。所以有些人把AlphaGo用的方法称为“通用的智能算法”，其实是言过其实的。

AlphaGo的算法，专门针对高手们常用的走法进行了优化。它根据数据分析，能够以>50%的准确率，预测人在很多情况下的走法。所以打败AlphaGo的一个有效方法，也许是使用“怪招”。也就是说，使用常人不会用的走法。这样一来，AlphaGo经过事先数据分析优化出来的“启发函数”就不再有用，从而陷入需要真正的“灵感”的困境。这样的怪招，也许是跟人对弈会失败的一招，然而对AlphaGo也许就是个沉重的打击。因为AlphaGo并没有足够的时间，当场计算出最佳方案，应付这样的怪招，也许就会导致一招走错，满盘皆输。

### AlphaGo不是人工智能历史性的突破

所以这次AlphaGo战胜了围棋冠军，跟之前IBM的“深蓝”电脑战胜国际象棋世界冠军，意义其实差不多。能够写出程序，在这些事情上打败世界冠军，的确是一个进步，这种技术会对某些特定的应用带来好处。然而，这并不说明AI取得了革命性的进步，更不能表明电脑具有了真正的智能。

恰恰相反，电脑能够在棋类游戏中战胜人类，正好说明了从事棋类活动的能力，并不足以衡量“人类智能”。我很早以前就发现，象棋围棋之类的游戏非常的无聊，比计算矩阵乘法还要烦。我为什么要干这样的事情，为了显示自己很聪明？那样其实很傻。所以作为一个智慧的生命体，我才懒得去自虐自己的脑筋。我应该写个程序去帮我做那些事情 :)

如果你想看到AI真正的希望，也许该看看这个视频：[乒乓球世界冠军险胜机械手](https://www.youtube.com/watch?v=tIIJME8-au8)…… 我跟你开玩笑的 :) 最后有人[揭露](http://www.dailymail.co.uk/sciencetech/article-2578633/The-Man-vs-Machine-table-tennis-showdown-went-viral-actual-cleverly-shot-TV-ad.html)，这是由KUKA机器人公司设计安排，经过大量剪辑，拍出来的广告而已。世界冠军[Timo Boll](https://en.wikipedia.org/wiki/Timo_Boll)，在其中只是一个演员。没有现场全程录像，没有观众，没有裁判，没有证人。Timo Boll配合他们，拍了一整天，只把那机械手最好的表现剪辑出来，犯笨的地方全都剪掉了。KUKA的机械手也许确实能打中球，然而完全不可能是普通人的对手，更不要说跟世界冠军交手。

虽然不能和人比，我发现KUKA的机械手作为一种工具，还挺有意思。有个[型号](https://www.youtube.com/watch?v=86Eu_YI38a0)甚至可以慢吞吞地做端茶倒水的动作。不过貌似比90岁老太太的敏捷程度还要差一些，而且只认得它自己那几个特定的物体，必须放在特定的位置。如果你给它换个形状的茶杯，或者给它斜着放，它应该就不知道该怎么办，因为它头脑里没有常识。

人是如何获得这些常识，如何表示它们，如何利用它们，仍然是未解之谜。所以为AlphaGo热血沸腾的人们，不要再沉迷于科幻和Skynet了。看清AI和“神经网络”的实质，用它们来做点有用的东西就可以了，可是不要对实现“人类智能”期望太高。
