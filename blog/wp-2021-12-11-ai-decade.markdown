最近又有人问我，为什么我认为“L4 自动驾驶”不可能实现，我才发现距离我的文章《[我看自动驾驶技术](http://www.yinwang.org/blog-cn/2016/02/12/self-driving-car)》，指出自动驾驶的根本性问题，已经快 8 年了。其实总结成一句话，驾驶车辆需要完整的人类认知，而所谓“机器学习”（深度学习）其实只是在拟合一个函数，完全无法提供认知能力。原理就不对。人类根本没有理解自己的智能是怎么回事，又怎么可能用机器实现它呢？

我第一眼就知道自动驾驶的 L1～L4 这种“分级”只是一个把戏，是设计来玩弄人们的智商的。很多人居然对它们认真了。设计一个游戏，打怪升级一样，让人误以为一步步地过了 L1，L2， L3，下一步就是 L4，而没有发现中间有一道不可逾越的鸿沟，永远无法到达彼岸。用虚无的“希望”来指引人们，说“再过两年就成功了！” 再过两年，又说“再过两年肯定就成功了！” …… 其实自己都不知道在朝哪里走。

8 年来，我目睹了人工智能领域的各种骗局，特别是自动驾驶领域的浮夸风。许多的自动驾驶公司的兴起和倒闭，一个个权威 AI 专家显露出他们本来的面目，整个 AI 领域的原形毕露。自动驾驶最后搞不成，就找别的出路，比如变成“辅助驾驶”公司。可是辅助驾驶这些技术，传统的汽车厂早就有了，怎么竞争呢？最后只有死路一条。

在其它很多领域，AI 也在败退。比如，我曾经以为深度学习能在医疗影像领域有所发展，可是最近听说它的效果也不好，难以“落地”。现在分析一下，神经网络看到一张 X 光片，它其实不知道看到的是什么。尽管已经给了它成千上万的“已标注”的 X 光片进行“训练”，它的能力也只是把这些不同的 X 光片区分开来，而不是真正能识别各种器官和骨骼。AI 领域大大地低估了“看 X 光片”这件事需要的“背景知识”。这需要真正的人类认知能力，而这不是神经网络可以实现的。所以它在医疗影像领域的失败，似乎也是可以预见的。

AI 领域一度夸大自己的能力，堂而皇之地以无知为荣。一个例子就是神经网络的“可解释性”。AI 领域总是宣传：“虽然结果没有可解释性，不知道是怎么来的，但它就是 work！” 起初人们觉得神奇：“看哪！我们可以不知道为什么，但它就是 work。很多难题原来可以这么解决，只要丢给它很多数据就可以了！”

过了很久才发现，那其实就是瞎蒙乱撞，并不能真的解决问题。几年以后通过各种失败，我们终于发现了这种可解释性的缺失，不是一个“美中不足”，而是一个致命弱点。为什么不具有可解释性呢？因为它根本不知道看见了什么。AI 领域让很多人妄想可以不知道自己在做什么却把事情做好，事实证明那是不可能的。

就这样，很多人 8 年的时间，被各种骗局偷走了。8 年有多长？可以上两次大学了。直接的间接的，所有人都受到影响。有多少人在自动驾驶公司工作，有多少人在大学里研究相关内容，把自己的人生规划在了这个方向。因为 AI 占据了大量的资本和资源，导致其他人也无事可做，被迫向资本靠拢，一起扯淡。有多少会点编译原理的人，都把自己的 title 改成了“Deep Learning Compiler Engineer”？世界发展陷于停顿，甚至倒退，太可怕了。我也为此荒废了不少时间。

再加上之前酝酿的时间，这事已经超过十年了。十年的错误认知，足以毁掉一代人。由于它对世界造成的严重影响，我觉得可以叫做“十年浩劫”了。

当人们从“科技梦”里醒来，就会看明白这一切都只是资本的游戏而已。AI 只是众多资本游戏里面很小的一个，昙花一现的配角。几年前就有投资人对我说：“我也知道 AI 领域是在骗钱，但我觉得是合理的。我们只是从更大的骗子们手里转移一点点资金来养活自己。所以你也去骗吧，你有这个资格。” 但因为原则和性格，我做不到。我无法与虚假生活在一起，那会让我失去自己。

虽然如此，我还是从中有收获的。AI 就像一面照妖镜，让我看明白了很多世间的事情。这是一场修行，它让我拨开迷雾，找回了更加原本的自己。
