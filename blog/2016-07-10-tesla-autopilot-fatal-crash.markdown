## Tesla autopilot 引起致命车祸

好一段时间没关心 Tesla 了，今天才发现他们的 autopilot 终于引起了[致命的车祸](http://www.pbs.org/newshour/rundown/deadly-tesla-crash-exposes-confusion-over-automated-driving)。这场 Model S 撞上18轮大卡车的车祸，发生于5月7号，距今已经两个月了。现在美国国家公路交通安全管理局（NHTSA）开始调查此事，才又成了话题。本来都懒得再提 Tesla 这公司的名字，但是由于 Tesla 对于这起车祸态度极不端正，找各种借口为 autopilot 开脱罪名，让这玩具级别的技术继续危害无辜开车人的安全，很多人（包括新闻机构）对此的分析很多都抓不住关键，所以我不得不再出来说几句。

死者名叫 [Joshua Brown](http://www.legacy.com/obituaries/ohio/obituary.aspx?pid=179994314)，40岁，曾作为炸弹专家，服役美国海军11年之久。退役以后成立了自己的技术公司，近段时间热衷于 Tesla 的电动车技术，还建立了一个 YouTube 频道，用于演示自己的 Tesla 车子。所以可以说，Joshua 对 Tesla 的 autopilot 使用方法已经很熟悉了。然而这不幸的事件，恰恰就发生在这个 Tesla 的专家用户和热心人身上。

Tesla 方面称，那天 Joshua 行驶在佛罗里达州一条中间有隔离带的公路上，合理的启用了 autopilot。行车途中，前方有一辆18轮卡车左转，由于卡车车厢是白色的，后面的天空也是白色，所以 autopilot 没看见这个卡车，没有进行刹车，最后 Model S 撞上卡车，车主身亡。白色卡车衬托在白色天空上，所以 autopilot 就把卡车当成空气，这是个什么情况……

先不说这技术有什么问题，出了这种事情，Tesla 对此[反应](https://www.teslamotors.com/en_GB/blog/tragic-loss)让人非常的失望。不但没有考虑过深刻反省和自我检查，反而各种狡辩和开脱。首先，他们从统计的角度，说明 Tesla 车引起死亡的比例，比其它车子小很多。然后旁敲侧击地想说明，就算是那人自己开车，也不能避免这种车祸。最后他们再三的强调，autopilot 的说明书已经声明，功能还不成熟，如果看到要出事而没有及时接管，你们自己负责！

这些都是 Tesla 老一套的诡辩方法。首先，Tesla 的死亡比例比其它车要小，并不能掩盖 autopilot 存在严重问题的事实。死亡比例小可能跟 Tesla 的技术没有很大关系，Tesla 是新公司，车都很新所以不容易出机械故障，而且买 Tesla 的都是有钱人，受过良好的教育，懂技术，所以一般不会乱开。那这种死亡比例，跟老牌子的车比是不公平的。其他牌子的车总数比 Tesla 多太多了，很多车子都十几二十年老掉牙，开车的各种人都有，酒鬼也有，老汉也有，罪犯也有，当然事故比例就上去了。如果你只看其它牌子最近几年的新车和豪华车，死亡比例拿来算一下，就很小。

如果你光看 autopilot 导航的总里程数，事故比例恐怕就上去了，因为很多 Tesla 用户可能没有启用 autopilot，或者用的很少。Autopilot 不是第一次引起车祸了，之前我的[另一篇文章](http://www.yinwang.org/blog-cn/2016/01/10/tesla-autopilot)已经提到，由于它的视觉技术不成熟，引发了许多险些发生车祸的情况，而且最近引起了好多次真正的车祸。要知道微小的比例落在一个人头上，就等于100%的不幸。等你因为 autopilot 而受害，才会发现 Tesla 摆出来的那些统计数字，对你其实毫无意义。也许，它确实造福了全人类，可惜死伤的人是你或者你的家人，而且那是因为 autopilot 极其弱智的判断错误…… 你会因为统计数字很安全而饶了 Tesla 吗？

另外 Tesla 喜欢旁敲侧击的指出 autopilot 的驾驶能力高于人类，而事实并不是那样。你怎么能证明人开车不能避免这车祸？Tesla 说：“驾驶员和 autopilot 都没有看到卡车。” 你们怎么知道驾驶员没有看见卡车？那可是18轮的大卡车！说白色的侧面车厢映在白色的天空，所以人看不见它，这不是搞笑吗。

一个东西是白色的，不等于它是看不见的，一个不透明的东西会挡住后面的景物，这一点人是很清楚的。白色的物体也会有反光，纹理会跟天空不一样，人可以通过这种反光感知它的存在。卡车不止有白色的侧面，还有黑色的轮子，车头上有烟囱，车窗，油箱，…… 各种其它颜色的附件。为了让其他人在夜间能看到车厢的大小，大卡车必须在车厢的八个角上都安装红色的警示灯，这些灯在白天不亮的时候也看得见的。就算天空是白色，人也是不可能看不见它，把卡车当成空气的。所以我猜真实情况是，驾驶员发现 autopilot 判断错误，想接管过来，但已经来不及了。要知道这个反应时间也许不到一秒！人死了，当然死无对证。

从多次的事故现象中，我分析出这样一个规律，虽然 Tesla 声称 Model S 上装备了雷达和声呐，但是 autopilot 的操作却似乎仅靠摄像头的“像素”，通过神经网络进行图像分析，所以它才会连18轮大卡车这么巨型的东西都没有发现，在路上看到个树影还以为是障碍物…… 这些都是人根本不会犯的奇葩错误。我请大家不要对自动驾驶技术过于乐观，急于求成。机器视觉在某些地方是很有用的技术，然而它要能被用于自动驾车，还有非常长的路要走。

Tesla 确实警告过人们，说这个技术还不成熟，你必须把手一直放在方向盘上，准备随时接管，然而这并不能免除 Tesla 的责任。首先，Tesla 根本就不应该把不成熟的技术发布出来，而且大肆宣传，搞得大家以为它很先进很可靠似的，争相试用。其次，说明书上的警告，在法律上也许是没有效力的。要人准备好随时接管，你必须在事发当时给出足够的警示，必须给人足够的响应时间，才能算是合理。

我们看到，autopilot 在道路情况超越了自己能力的时候，并不能给人提示，以至于人根本不知道它出了问题，不能及时的接管，以至于直接撞上卡车。要知道，车在直走的时候，autopilot 是否出了故障你往往是看不出来的，等你发现它没有刹车，那个时候就已经晚了。人要扶着方向盘，还要随时监督 autopilot 的行为，生怕它犯错，那还不如自己开车轻松呢。这就像监督一个顽皮的小孩做饭，怕他被锅烫到，被刀割到，怕他把地板弄成浆糊…… 这可比自己做饭累多了！

所以在这种情况下，Tesla 虽然事先有“免责声明”，在法庭上其实仍然可以败诉。我建议这起车祸死者的家属把 Tesla 告上法庭，要求巨额赔偿。我也建议所有 Tesla 的车主，为了对自己和他人的生命负责，别再使用 autopilot 这样致命的玩具了！Tesla 根本就不懂如何设计自动驾驶系统，技术不过硬，设计有缺陷，别再被他们所谓的“先进技术”蒙骗了。
